# Comment-Toxdetect-Model
A deep learning-based project that detects toxic comments from user-generated content. This project leverages Natural Language Processing (NLP) techniques and a bidirectional LSTM (Long Short-Term Memory) model to classify comments as toxic or non-toxic. The model achieves high accuracy, precision, and recall, demonstrating its robustness in identifying harmful language while minimizing false positives. The project also includes a user-friendly frontend built with Streamlit.

**Explore the Live Project at**-https://comment-toxdetect-l9exdnlcdrwyvzcswvynqp.streamlit.app

# Installation

# Prerequisites
- Python 3.10.x installed on your system.

# Steps

1. **Clone the repository**
    ```bash
    git clone https://github.com/singhsamarth/Comment-Toxdetect.git
    ```

2. **Navigate to the repository folder**
    ```bash
    cd Comment-Toxdetect
    ```

3. **Install the required dependencies**
    ```bash
    pip install -r requirements.txt
    ```

4. **Run the Streamlit application**
    ```bash
    streamlit run front.py
    ```

5. **Open your browser and navigate to:**
    ```bash
    http://localhost:8501
    ```
    

